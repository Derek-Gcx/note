{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.10 64-bit ('dev': conda)",
   "metadata": {
    "interpreter": {
     "hash": "52161b8878062e0183138be9677c3f12f42cd1f503559b4700bfaa5a2ad66d53"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# pytorch数据加载"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "from skimage import io, transform\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "plt.ion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "landmarks_frame = pd.read_csv(\"/home/derek/Documents/mm/resources/2020/dataset/faces/face_landmarks.csv\")\n",
    "root = \"/home/derek/Documents/mm/resources/2020/dataset/faces/\"\n",
    "\n",
    "def show_landmarks(image, landmarks):\n",
    "    plt.imshow(image)\n",
    "    plt.scatter(landmarks[:, 0], landmarks[:, 1], s=10, marker=\".\", c=\"r\")\n",
    "    plt.pause(0.001)\n",
    "\n",
    "n = 65\n",
    "name = landmarks_frame.iloc[n, 0]\n",
    "landmarks = np.asarray(landmarks_frame.iloc[n, 1:], dtype=float).reshape(-1, 2)\n",
    "# show_landmarks(io.imread(os.path.join(root, name)), landmarks)\n",
    "\n"
   ]
  },
  {
   "source": [
    "## Loading dataset with `Dataset`"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "class FaceLandmarksDataset(Dataset):\n",
    "    def __init__(self, csv_file, root_dir, transform=None):\n",
    "        self.landmarks_frame = pd.read_csv(os.path.join(root_dir, csv_file))\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "        # self.FaceLandmarkTuple = namedtuple(\"FaceLandmarkTuple\", [\"image\", \"landmarks\"])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.landmarks_frame)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # ATTENTION, here idx may be a tensor\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        # may fail when idx is an array of index\n",
    "        img_name = os.path.join(self.root_dir, \n",
    "                                self.landmarks_frame.iloc[idx, 0])\n",
    "        image = io.imread(img_name)\n",
    "        landmarks = np.asarray(self.landmarks_frame.iloc[idx, 1:], dtype=float).reshape(-1, 2)\n",
    "\n",
    "        # can sample be a named tuple here?\n",
    "        sample = {\"image\":image, \"landmarks\":landmarks}\n",
    "        # sample = self.FaceLandmarkTuple(image, landmarks)\n",
    "\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_dataset = FaceLandmarksDataset(csv_file=\"face_landmarks.csv\", root_dir=root)"
   ]
  },
  {
   "source": [
    "## Pre-processing dataset using `Transform`"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Rescale(object):\n",
    "    def __init__(self, output_size):\n",
    "        assert isinstance(output_size, (int, tuple))\n",
    "        self.output_size = output_size\n",
    "    def __call__(self, sample):\n",
    "        image, landmarks = sample[\"image\"],sample[\"landmarks\"]\n",
    "        h, w = image.shape[0:2] # 可能还有通道数\n",
    "        if isinstance(self.output_size, int):\n",
    "            if h>w:\n",
    "                new_h, new_w = self.output_size*h/w, self.output_size\n",
    "            else:\n",
    "                new_h, new_w = self.output_size, self.output_size*w/h\n",
    "        else:\n",
    "            new_h, new_w = self.output_size\n",
    "        new_h, new_w = int(new_h), int(new_w)\n",
    "        img = transform.resize(image, (new_h, new_w))\n",
    "        landmarks = landmarks * [new_w/w, new_h/h]\n",
    "        return {\"image\":img, \n",
    "                \"landmarks\":landmarks}\n",
    "# # help(transform.resize)\n",
    "# sample = face_dataset[0]\n",
    "# fn = Rescale((300,200))\n",
    "# # sample = fn(sample)\n",
    "# plt.subplot(131)\n",
    "# show_landmarks(sample[\"image\"], sample[\"landmarks\"])\n",
    "# plt.subplot(132)\n",
    "# sample = fn(sample)\n",
    "# show_landmarks(sample[\"image\"], sample[\"landmarks\"])\n",
    "# plt.subplot(133)\n",
    "# fn = Rescale((300,100))\n",
    "# sample = fn(sample)\n",
    "# show_landmarks(sample[\"image\"], sample[\"landmarks\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomCrop(object):\n",
    "    def __init__(self, output_size):\n",
    "        assert isinstance(output_size, (int, tuple))\n",
    "        if isinstance(output_size, int):\n",
    "            self.output_size = (output_size, output_size)\n",
    "        else:\n",
    "            assert len(output_size) == 2\n",
    "            self.output_size = output_size\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        image, landmarks = sample['image'], sample['landmarks']\n",
    "\n",
    "        h, w = image.shape[:2]\n",
    "        new_h, new_w = self.output_size\n",
    "\n",
    "        top = np.random.randint(0, h - new_h)\n",
    "        left = np.random.randint(0, w - new_w)\n",
    "\n",
    "        image = image[top: top + new_h,\n",
    "                      left: left + new_w]\n",
    "\n",
    "        landmarks = landmarks - [left, top]\n",
    "\n",
    "        return {'image': image, 'landmarks': landmarks}\n",
    "\n",
    "class ToTensor(object):\n",
    "    def __call__(self, sample):\n",
    "        image, landmarks = sample['image'], sample['landmarks']\n",
    "        image = image.transpose((2, 0, 1))\n",
    "        return {'image': torch.from_numpy(image),\n",
    "                'landmarks': torch.from_numpy(landmarks)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 下面定义一个transform的pipeline，组合上述操作\n",
    "transformed_dataset = FaceLandmarksDataset(\n",
    "    csv_file = \"face_landmarks.csv\", \n",
    "    root_dir=root, \n",
    "    transform=transforms.Compose([\n",
    "        Rescale(256), \n",
    "        RandomCrop(224), \n",
    "        ToTensor()\n",
    "    ])\n",
    ")"
   ]
  },
  {
   "source": [
    "## Iterating dataset with `DataLoader`\n",
    "Iterating `Dataset` by `enumerate(dataset)` fails to \n",
    "+ Batching the data\n",
    "+ Shuffling the data\n",
    "+ Load the data in parallel using `multiproxessing` workers\n",
    "So we use `DataLoader` to iterate the dataset instead, in which the above features are well-integrated."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "dataloader = DataLoader(transformed_dataset, batch_size=4, shuffle=True, num_workers=0)\n"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 51,
   "outputs": []
  },
  {
   "source": [
    "## Use `collate_fn` to deal with different data types of dataset\n",
    "+ if `Dataset.__getitem__()` returns a `dict`, then the default collate_fn merges entries on their key, and return a `dict`.\n",
    "+ if `Dataset.__getitem__()` returns a `namedtuple` or `list`, then the default collate_fn concate the elements of the entry based on their idx, and returns a list of tensor. The length of the list equals the length of the entry. \n",
    "+ Both the default collate_fns mentioned above will try to convert the data to tensor at last. If the data cannot be converted to tensor (such as inconsistent lengths or dtypes), an error will be raised. \n",
    "+ To handle this, you can use a customized collate_fn to merge the entries in your dataset.  "
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}